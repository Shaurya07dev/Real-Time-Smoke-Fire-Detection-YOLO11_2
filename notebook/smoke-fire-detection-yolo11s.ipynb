{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **How to Train YOLO11 Object Detection Model on a Custom Dataset**","metadata":{"id":"Xf01JEu1Rqkd"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"iB8A5n5uRf-r","outputId":"7583b64d-5326-4564-d111-c04a2b8fd705","trusted":true,"execution":{"iopub.status.busy":"2025-01-24T04:37:30.882804Z","iopub.execute_input":"2025-01-24T04:37:30.883131Z","iopub.status.idle":"2025-01-24T04:37:31.046169Z","shell.execute_reply.started":"2025-01-24T04:37:30.883102Z","shell.execute_reply":"2025-01-24T04:37:31.045289Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Step 01 # Install the Ultralytics Package**","metadata":{"id":"gYrzZil_R9e8"}},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"id":"Lrt8kAH2R5IH","outputId":"cf6e646e-447f-4a36-fa1a-66b1cccbd3b9","trusted":true,"execution":{"iopub.status.busy":"2025-01-24T04:37:31.362628Z","iopub.execute_input":"2025-01-24T04:37:31.362925Z","iopub.status.idle":"2025-01-24T04:37:36.555761Z","shell.execute_reply.started":"2025-01-24T04:37:31.362898Z","shell.execute_reply":"2025-01-24T04:37:36.554729Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Step 02 # Import All the Requried Libraries**","metadata":{"id":"7UavftMRSJhe"}},{"cell_type":"code","source":"import ultralytics\nultralytics.checks()","metadata":{"id":"OKI6XspoSkdc","outputId":"7d63486c-ea2f-4e1e-d330-678dbe7e85d4","trusted":true,"execution":{"iopub.status.busy":"2025-01-24T04:37:36.557022Z","iopub.execute_input":"2025-01-24T04:37:36.557354Z","iopub.status.idle":"2025-01-24T04:37:40.563635Z","shell.execute_reply.started":"2025-01-24T04:37:36.557318Z","shell.execute_reply":"2025-01-24T04:37:40.562966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nfrom IPython.display import Image","metadata":{"id":"oHWcOSblSGg8","trusted":true,"execution":{"iopub.status.busy":"2025-01-24T04:37:40.565100Z","iopub.execute_input":"2025-01-24T04:37:40.565474Z","iopub.status.idle":"2025-01-24T04:37:40.568848Z","shell.execute_reply.started":"2025-01-24T04:37:40.565450Z","shell.execute_reply":"2025-01-24T04:37:40.568064Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Step # 03 Download Dataset from Roboflow**","metadata":{"id":"x1Nv8H2mS41D"}},{"cell_type":"code","source":"# import shutil\n\n# shutil.rmtree('/kaggle/working/Fire-and-Smoke-Dataset-2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T04:37:40.569976Z","iopub.execute_input":"2025-01-24T04:37:40.570322Z","iopub.status.idle":"2025-01-24T04:37:40.586829Z","shell.execute_reply.started":"2025-01-24T04:37:40.570289Z","shell.execute_reply":"2025-01-24T04:37:40.586007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"anE8f8mHUPRzhLiMZlkH\")\nproject = rf.workspace(\"capstone-project-ah5nl\").project(\"fire-and-smoke-dataset-d72ll\")\nversion = project.version(2)\ndataset = version.download(\"yolov11\")\n                ","metadata":{"id":"E9wKYZvASY3U","outputId":"9ef2f6d8-19fe-415a-c079-eb164d2f37d4","trusted":true,"execution":{"iopub.status.busy":"2025-01-24T04:37:40.587666Z","iopub.execute_input":"2025-01-24T04:37:40.587959Z","iopub.status.idle":"2025-01-24T04:37:51.340361Z","shell.execute_reply.started":"2025-01-24T04:37:40.587931Z","shell.execute_reply":"2025-01-24T04:37:51.339570Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset.location","metadata":{"id":"mdZobxnHVhhf","outputId":"ccf5dbf8-4d79-42bc-8474-1fc6f516bd88","trusted":true,"execution":{"iopub.status.busy":"2025-01-24T04:37:51.341366Z","iopub.execute_input":"2025-01-24T04:37:51.341657Z","iopub.status.idle":"2025-01-24T04:37:51.347583Z","shell.execute_reply.started":"2025-01-24T04:37:51.341632Z","shell.execute_reply":"2025-01-24T04:37:51.346859Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Path correction","metadata":{}},{"cell_type":"code","source":"import yaml\n\n# Path to the YAML file\nfile_path = f'{dataset.location}/data.yaml'\n\n# Step 1: Read the YAML file\nwith open(file_path, 'r') as file:\n    data = yaml.safe_load(file)\n\n# Step 2: Update paths for train, val, and test\nbase_path = dataset.location\ndata['train'] = f\"{base_path}/train/images\"\ndata['val'] = f\"{base_path}/valid/images\"\ndata['test'] = f\"{base_path}/test/images\"\n\n# Step 3: Save the updated YAML data back to the file\nwith open(file_path, 'w') as file:\n    yaml.safe_dump(data, file, default_flow_style=False)\n\nprint(\"Paths updated successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T04:37:51.348335Z","iopub.execute_input":"2025-01-24T04:37:51.348645Z","iopub.status.idle":"2025-01-24T04:37:51.366765Z","shell.execute_reply.started":"2025-01-24T04:37:51.348608Z","shell.execute_reply":"2025-01-24T04:37:51.365951Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Verification","metadata":{}},{"cell_type":"code","source":"from pprint import pprint\nwith open(file_path, 'r') as file:\n    updated_data = yaml.safe_load(file)\n    pprint(updated_data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T04:37:51.368355Z","iopub.execute_input":"2025-01-24T04:37:51.368578Z","iopub.status.idle":"2025-01-24T04:37:51.387521Z","shell.execute_reply.started":"2025-01-24T04:37:51.368560Z","shell.execute_reply":"2025-01-24T04:37:51.386879Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Labels Clearning","metadata":{}},{"cell_type":"markdown","source":"I noticed that labels contains invalid boxes and duplicates.","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nimport logging\n\nclass YOLODatasetPreprocessor:\n    def __init__(self, dataset_path):\n        self.dataset_path = dataset_path\n        self.splits = ['train', 'valid', 'test']\n\n        self.original_logging_handlers = logging.root.handlers.copy()\n        # Configure logging\n        log_filename = '/kaggle/working/dataset_preprocessing.log'\n        os.makedirs(os.path.dirname(log_filename), exist_ok=True)\n\n        # Clear any existing logging configuration\n        for handler in logging.root.handlers[:]:\n            logging.root.removeHandler(handler)\n\n        # Set up logging\n        logging.basicConfig(\n            level=logging.INFO,\n            format='%(asctime)s - %(levelname)s: %(message)s',\n            handlers=[\n                logging.FileHandler(log_filename),\n                logging.StreamHandler()\n            ]\n        )\n        self.logger = logging.getLogger(__name__)\n\n    def is_valid_bbox(self, bbox_coords):\n        \"\"\"Validate YOLO bbox coordinates\"\"\"\n        return (len(bbox_coords) == 4 and all(0 <= coord <= 1 for coord in bbox_coords))\n\n    def process_labels(self):\n        \"\"\"Robust label processing with strict validation\"\"\"\n        total_processed_files = 0\n        total_converted_labels = 0\n\n        for split in self.splits:\n            labels_dir = os.path.join(self.dataset_path, split, 'labels')\n\n            if not os.path.exists(labels_dir):\n                self.logger.warning(f\"Labels directory not found for split {split}\")\n                continue\n\n            for label_file in os.listdir(labels_dir):\n                label_path = os.path.join(labels_dir, label_file)\n\n                with open(label_path, 'r') as f:\n                    lines = f.readlines()\n\n                cleaned_lines = []\n                processed_count = 0\n\n                for line in lines:\n                    parts = line.strip().split()\n\n                    # Validate basic label structure\n                    if len(parts) < 5:\n                        self.logger.warning(f\"Invalid label in {label_file}: {line.strip()}\")\n                        processed_count += 1\n                        continue\n\n                    try:\n                        class_idx = int(parts[0])\n                        coords = list(map(float, parts[1:]))\n\n                        # Standard YOLO bbox\n                        if self.is_valid_bbox(coords):\n                            cleaned_lines.append(line)\n                            continue\n\n                        # Polygon conversion attempt\n                        if len(coords) >= 6 and len(coords) % 2 == 0:\n                            x_coords = coords[0::2]\n                            y_coords = coords[1::2]\n\n                            x_min, x_max = min(x_coords), max(x_coords)\n                            y_min, y_max = min(y_coords), max(y_coords)\n\n                            width = round(x_max - x_min, 5)\n                            height = round(y_max - y_min, 5)\n\n                            center_x = round(x_min + width / 2, 5)\n                            center_y = round(y_min + height / 2, 5)\n\n                            new_bbox = [center_x, center_y, width, height]\n\n                            if self.is_valid_bbox(new_bbox):\n                                new_line = f\"{class_idx} {new_bbox[0]} {new_bbox[1]} {new_bbox[2]} {new_bbox[3]}\\n\"\n                                cleaned_lines.append(new_line)\n                                processed_count += 1\n                            else:\n                                self.logger.warning(f\"Invalid converted bbox in {label_file}\")\n                        else:\n                            self.logger.warning(f\"Unprocessable label in {label_file}: {line.strip()}\")\n\n                    except (ValueError, IndexError) as e:\n                        self.logger.error(f\"Error processing label in {label_file}: {line.strip()} - {e}\")\n\n                # Only write if changes were detected\n                if len(set(cleaned_lines)) != len(cleaned_lines):\n                    self.logger.warning(f\"Duplicates detected in {label_file}: {len(lines)-len(set(cleaned_lines))} duplicates\")\n                    processed_count += (len(cleaned_lines) - len(set(cleaned_lines)))\n                    cleaned_lines = list(set(cleaned_lines))\n\n                if processed_count:\n                    with open(label_path, 'w') as f:\n                        f.writelines(cleaned_lines)\n                    self.logger.info(f\"Processed {label_file}: {processed_count} labels\")\n                    total_processed_files += 1\n                    total_converted_labels += processed_count\n\n        self.logger.info(f\"Total processed files: {total_processed_files}\")\n        self.logger.info(f\"Total converted labels: {total_converted_labels}\")\n\n    def validate_dataset(self):\n        \"\"\"Comprehensive dataset validation\"\"\"\n        is_valid = True\n        validation_report = {\n            'missing_directories': [],\n            'missing_labels': {},\n            'duplicate_labels': []\n        }\n\n        for split in self.splits:\n            images_dir = os.path.join(self.dataset_path, split, 'images')\n            labels_dir = os.path.join(self.dataset_path, split, 'labels')\n\n            if not (os.path.exists(images_dir) and os.path.exists(labels_dir)):\n                self.logger.warning(f\"Missing directories in {split}\")\n                validation_report['missing_directories'].append(split)\n                is_valid = False\n                continue\n\n            image_files = set(os.listdir(images_dir))\n            label_files = set(os.listdir(labels_dir))\n\n            # Check matching images and labels\n            expected_labels = {f.rsplit('.', 1)[0] + '.txt' for f in image_files}\n            missing_labels = expected_labels - label_files\n\n            if missing_labels:\n                self.logger.warning(f\"Missing labels in {split}: {missing_labels}\")\n                validation_report['missing_labels'][split] = missing_labels\n                is_valid = False\n\n            # Duplicate label validation\n            for label_file in label_files:\n                label_path = os.path.join(labels_dir, label_file)\n                with open(label_path, 'r') as f:\n                    lines = f.readlines()\n\n                # Check for duplicate labels within the file\n                unique_labels = set(lines)\n                if len(unique_labels) != len(lines):\n                    self.logger.warning(f\"Duplicate labels found in {label_file}\")\n                    validation_report['duplicate_labels'].append(label_file)\n                    is_valid = False\n\n        return is_valid, validation_report\n\n    def backup_dataset(self):\n        \"\"\"Create a backup of the entire dataset\"\"\"\n        backup_dir = os.path.join(self.dataset_path, 'backup')\n        shutil.copytree(self.dataset_path, backup_dir, dirs_exist_ok=True)\n        self.logger.info(f\"Dataset backed up to {backup_dir}\")\n        return backup_dir\n\n    def preprocess(self):\n        \"\"\"Run full preprocessing pipeline\"\"\"\n        self.logger.info(\"Starting dataset preprocessing...\")\n\n        # Backup dataset\n        backup_path = self.backup_dataset()\n\n        # Initial validation\n        self.logger.info(\"Performing initial dataset validation...\")\n        initial_valid, initial_report = self.validate_dataset()\n        self.logger.info(f\"Initial dataset validation: {'Valid' if initial_valid else 'Invalid'}\")\n\n        # Process labels\n        self.logger.info(\"Processing labels...\")\n        self.process_labels()\n\n        # Final validation\n        self.logger.info(\"Performing final dataset validation...\")\n        final_valid, final_report = self.validate_dataset()\n\n        # Generate comprehensive report\n        self.generate_preprocessing_report(backup_path, initial_valid, initial_report, final_valid, final_report)\n\n        return final_valid\n\n    def generate_preprocessing_report(self, backup_path, initial_valid, initial_report, final_valid, final_report):\n        \"\"\"Generate a comprehensive preprocessing report\"\"\"\n        self.logger.info(\"=\" * 50)\n        self.logger.info(\"YOLO DATASET PREPROCESSING REPORT\")\n        self.logger.info(\"=\" * 50)\n\n        self.logger.info(f\"Dataset Path: {self.dataset_path}\")\n        self.logger.info(f\"Backup Path: {backup_path}\")\n\n        self.logger.info(\"Initial Validation:\")\n        self.logger.info(f\"Overall Status: {'Valid' if initial_valid else 'Invalid'}\")\n        self.logger.info(f\"Missing Directories: {initial_report['missing_directories']}\")\n        self.logger.info(f\"Missing Labels: {initial_report['missing_labels']}\")\n        self.logger.info(f\"Duplicate Labels: {initial_report['duplicate_labels']}\")\n\n        self.logger.info(\"Final Validation:\")\n        self.logger.info(f\"Overall Status: {'Valid' if final_valid else 'Invalid'}\")\n        self.logger.info(f\"Missing Directories: {final_report['missing_directories']}\")\n        self.logger.info(f\"Missing Labels: {final_report['missing_labels']}\")\n        self.logger.info(f\"Duplicate Labels: {final_report['duplicate_labels']}\")\n\n\ndef main():\n    dataset_path = \"/kaggle/working/Fire-and-Smoke-Dataset-2\"  # Updated path for Kaggle\n    try:\n        preprocessor = YOLODatasetPreprocessor(dataset_path)\n        is_valid = preprocessor.preprocess()\n\n        if is_valid:\n            print(\"Dataset preprocessing completed successfully!\")\n        else:\n            print(\"Dataset preprocessing completed with some issues. Check the logs for details at '/kaggle/working/dataset_preprocessing.log'.\")\n\n    except Exception as e:\n        logging.error(f\"Preprocessing Failed: {e}\")\n\n    finally:\n        # Explicitly restore logging configuration\n        for handler in logging.root.handlers[:]:\n            logging.root.removeHandler(handler)\n        for handler in preprocessor.original_logging_handlers:\n            logging.root.addHandler(handler)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T04:38:02.441963Z","iopub.execute_input":"2025-01-24T04:38:02.442340Z","iopub.status.idle":"2025-01-24T04:38:02.587037Z","shell.execute_reply.started":"2025-01-24T04:38:02.442311Z","shell.execute_reply":"2025-01-24T04:38:02.586011Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T04:38:05.247554Z","iopub.execute_input":"2025-01-24T04:38:05.247875Z","iopub.status.idle":"2025-01-24T04:38:07.031229Z","shell.execute_reply.started":"2025-01-24T04:38:05.247847Z","shell.execute_reply":"2025-01-24T04:38:07.030350Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Testing Cleaning Code","metadata":{}},{"cell_type":"markdown","source":"**Step # 04 Train YOLO11 Model on a Custom Dataset**","metadata":{"id":"B_cfUufNYF3_"}},{"cell_type":"code","source":"!yolo task=detect mode=train data={dataset.location}/data.yaml model=\"yolo11s.pt\" epochs=55 imgsz=640 batch=16 patience=6","metadata":{"id":"yxp_shPlYBAS","outputId":"4fba4096-5403-4214-fa32-1c835ffbdf34","trusted":true,"execution":{"iopub.status.busy":"2025-01-24T04:38:28.935736Z","iopub.execute_input":"2025-01-24T04:38:28.936049Z","execution_failed":"2025-01-24T04:53:09.129Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Step # 05 Examine Training Results**","metadata":{"id":"gFLPh2gN04R_"}},{"cell_type":"code","source":"Image(\"/kaggle/working/runs/detect/train/confusion_matrix.png\", width=600)","metadata":{"id":"vHVXACym1VZk","outputId":"51a34924-610d-420c-defb-baecd413ef06","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T21:26:01.832550Z","iopub.execute_input":"2025-01-23T21:26:01.832903Z","iopub.status.idle":"2025-01-23T21:26:01.851594Z","shell.execute_reply.started":"2025-01-23T21:26:01.832876Z","shell.execute_reply":"2025-01-23T21:26:01.850801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Image(\"/kaggle/working/runs/detect/train/labels.jpg\", width=600)","metadata":{"id":"Hh2vau2HMuc_","outputId":"678b11bc-fa1b-4a42-aa12-14601fb4a033","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T21:26:07.565917Z","iopub.execute_input":"2025-01-23T21:26:07.566262Z","iopub.status.idle":"2025-01-23T21:26:07.589932Z","shell.execute_reply.started":"2025-01-23T21:26:07.566236Z","shell.execute_reply":"2025-01-23T21:26:07.588832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Image(\"/kaggle/working/runs/detect/train/results.png\", width=600)","metadata":{"id":"PeSiFrwP1tbF","outputId":"96f2786b-61be-48be-e5b8-a2011d0ea996","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T21:26:13.149679Z","iopub.execute_input":"2025-01-23T21:26:13.150042Z","iopub.status.idle":"2025-01-23T21:26:13.165252Z","shell.execute_reply.started":"2025-01-23T21:26:13.150016Z","shell.execute_reply":"2025-01-23T21:26:13.164504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Image(\"/kaggle/working/runs/detect/train/train_batch0.jpg\", width=600)","metadata":{"id":"RacyVWK3103E","outputId":"d67f94bf-f64e-4c0b-a962-d856ac38605d","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T21:26:21.043367Z","iopub.execute_input":"2025-01-23T21:26:21.043682Z","iopub.status.idle":"2025-01-23T21:26:21.064663Z","shell.execute_reply.started":"2025-01-23T21:26:21.043657Z","shell.execute_reply":"2025-01-23T21:26:21.063599Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Image(\"/kaggle/working/runs/detect/train/val_batch0_pred.jpg\", width=600)","metadata":{"id":"idaZDidT10_L","outputId":"0b5e75b5-797d-405d-daa2-84224eecfc95","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T21:26:45.623243Z","iopub.execute_input":"2025-01-23T21:26:45.623558Z","iopub.status.idle":"2025-01-23T21:26:45.637270Z","shell.execute_reply.started":"2025-01-23T21:26:45.623535Z","shell.execute_reply":"2025-01-23T21:26:45.636577Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Image(\"/kaggle/working/runs/detect/train/val_batch1_pred.jpg\", width=600)","metadata":{"id":"VPEj-hRA11Pn","outputId":"c9543d5b-6847-4445-9509-968b14984738","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T21:26:52.346794Z","iopub.execute_input":"2025-01-23T21:26:52.347120Z","iopub.status.idle":"2025-01-23T21:26:52.362925Z","shell.execute_reply.started":"2025-01-23T21:26:52.347096Z","shell.execute_reply":"2025-01-23T21:26:52.362046Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Step # 07  Validate Fine-Tuned Model**","metadata":{"id":"alfU2d0z41X6"}},{"cell_type":"code","source":"!yolo task=detect mode=val model=\"/kaggle/working/runs/detect/train/weights/best.pt\" data={dataset.location}/data.yaml","metadata":{"id":"Ot3DOqCoYfsk","outputId":"68370654-724e-45e1-8081-4c723cee2973","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T21:27:05.926913Z","iopub.execute_input":"2025-01-23T21:27:05.927242Z","iopub.status.idle":"2025-01-23T21:27:14.990513Z","shell.execute_reply.started":"2025-01-23T21:27:05.927220Z","shell.execute_reply":"2025-01-23T21:27:14.989358Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Step # 08 Inference with Custom Model on Images**","metadata":{"id":"OOdt0GSA5ntm"}},{"cell_type":"code","source":"!yolo task=detect mode=predict model=\"/kaggle/working/runs/detect/train/weights/best.pt\" conf=0.25 source={dataset.location}/test/images save=True","metadata":{"id":"E1dU-fiz3sUr","outputId":"97f98888-2b44-4f0f-83cd-249f04bcdf64","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T21:27:20.989017Z","iopub.execute_input":"2025-01-23T21:27:20.989391Z","iopub.status.idle":"2025-01-23T21:27:38.586536Z","shell.execute_reply.started":"2025-01-23T21:27:20.989354Z","shell.execute_reply":"2025-01-23T21:27:38.585640Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob\nimport os\nfrom IPython.display import Image as IPyImage, display\n\nlatest_folder = max(glob.glob('/kaggle/working/runs/detect/predict*/'), key=os.path.getmtime)\nfor img in glob.glob(f'{latest_folder}/*.jpg')[1:4]:\n    display(IPyImage(filename=img, width=600))\n    print(\"\\n\")","metadata":{"id":"ovHNzaN76tNT","outputId":"82803388-8ea9-43fc-fa04-69d8c1ecec91","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T21:27:42.677470Z","iopub.execute_input":"2025-01-23T21:27:42.677803Z","iopub.status.idle":"2025-01-23T21:27:42.755829Z","shell.execute_reply.started":"2025-01-23T21:27:42.677775Z","shell.execute_reply":"2025-01-23T21:27:42.754582Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}